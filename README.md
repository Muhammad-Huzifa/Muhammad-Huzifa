<div align="center">
  
# ğŸ‘‹ Hi, I'm Muhammad Huzaifa

<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=28&duration=3000&pause=1000&color=9745F5&center=true&vCenter=true&multiline=false&repeat=true&width=900&lines=Deep+Learning+Researcher+%26+Engineer;Spatio-Temporal+AI+%7C+Graph+Neural+Networks;Sign+Language+Recognition+Specialist;Building+Efficient+AI+Systems+from+Scratch" alt="Typing SVG" />

[![GitHub followers](https://img.shields.io/github/followers/Muhammad-Huzifa?style=social)](https://github.com/Muhammad-Huzifa)
[![Profile Views](https://komarev.com/ghpvc/?username=Muhammad-Huzifa&color=blueviolet&style=flat-square&label=Profile+Views)](https://github.com/Muhammad-Huzifa)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/muhammad-huzifa3202/)
[![Email](https://img.shields.io/badge/Email-Contact-EA4335?style=flat-square&logo=gmail)](mailto:mhuzaifa3202@gmail.com)

</div>

---

## ğŸ“ About Me

I am a **Computer Scientist** (BS, **Islamia College University, Peshawar**, 2021â€“2025) specializing in **Deep Learning**, **Computer Vision**, and **Spatio-Temporal AI**. Currently conducting research on **Sign Language Recognition** using cutting-edge Graph Neural Networks and Transformer architectures.

My work focuses on developing **efficient, lightweight, and scalable AI systems** that bridge the gap between academic research and real-world deployment. I build models from first principles, implementing custom architectures and training pipelines to achieve optimal performance with minimal computational overhead.

ğŸ”¬ **Active Research Areas:**
- **Spatio-Temporal Graph Convolutional Networks (ST-GCNs)** for skeleton-based action recognition
- **Transformer-based Temporal Modeling** for sequential data
- **Pose Estimation & Landmark Extraction** using MediaPipe
- **Hybrid Architectures** (GCN + Transformer + BiLSTM)
- **Lightweight Model Design** for edge deployment (<1M parameters)
- **Multi-Stream Fusion Strategies** for dual-modality learning

ğŸ’¼ **Currently Working On:**
> ğŸš€ Developing **TT-STGCN (Temporal Transformer ST-GCN)** â€” A novel architecture for Isolated Sign Language Recognition achieving 85%+ accuracy on WLASL-300 dataset with only 850K parameters.

---

## ğŸ”¥ Featured Research Projects

<div align="center">

### **ğŸ† Final Year Project: Sign Language Recognition Systems**

</div>

> **âš¡ These repositories represent my core research contributions in developing efficient, state-of-the-art models for gesture-based communication.**

<table>
<tr>
<td width="50%">

### 1ï¸âƒ£ [TT-STGCN for Sign Language Recognition](https://github.com/Muhammad-Huzifa/TT-STGCN-for-Sign-Language-Recognition)

**ğŸ¯ Primary Research Implementation**

- **Architecture**: Temporal Transformer + Spatial-Temporal GCN
- **Innovation**: Dual-stream (Joint + Bone) processing with cross-attention fusion
- **Performance**: 74%+ Top-1 accuracy on 300 classes
- **Efficiency**: ~1M parameters (3.4 MB model)
- **Tech Stack**: PyTorch, MediaPipe, Graph Neural Networks

**Key Features:**
- âœ… Lightweight Transformer blocks for temporal modeling
- âœ… Adaptive graph convolution with learnable adjacency
- âœ… Multi-scale temporal pooling
- âœ… Advanced augmentation pipeline (mixup, temporal masking)

</td>
<td width="50%">

### 2ï¸âƒ£ [Efficient TT-STGCN](https://github.com/Muhammad-Huzifa/Efficient-TT-STGCN-for-Sign-Language-Recognition)

**âš¡ Ultra-Lightweight Variant**

- **Architecture**: Depthwise Separable ST-GCN
- **Innovation**: Parameter-efficient design (<300K params)
- **Performance**: 71% Top-1 accuracy (267K parameters)
- **Efficiency**: Only 1.02 MB model size
- **Deployment**: Optimized for edge devices (RTX 3050)

**Key Features:**
- âœ… Depthwise separable convolutions (8-9x param reduction)
- âœ… Simple attention mechanisms (2-layer)
- âœ… Reduced adjacency subsets (2 instead of 3)
- âœ… Real-time inference (~18ms/sample)

</td>
</tr>
</table>

<table>
<tr>
<td width="50%">

### 3ï¸âƒ£ [ISLR Using ST-GCN](https://github.com/Muhammad-Huzifa/ISLR-Using-STGCN)

**ğŸ“Š Baseline ST-GCN Implementation**

- **Architecture**: Classic Spatial-Temporal GCN
- **Focus**: Foundational graph-based approach
- **Dataset**: WLASL-300 (isolated signs)
- **Contribution**: Clean, well-documented baseline

**Key Contributions:**
- âœ… Complete ST-GCN implementation from scratch
- âœ… MediaPipe landmark extraction pipeline
- âœ… Graph topology for 65 body joints (pose + hands)
- âœ… Training optimizations (label smoothing, cosine annealing)

</td>
<td width="50%">

### 4ï¸âƒ£ [ISLR with BiLSTM + Attention](https://github.com/Muhammad-Huzifa/ISLR-Landmarks-using-BiLSTM-with-Attention-Mechanism)

**ğŸ§  Sequential Modeling Approach**

- **Architecture**: Bidirectional LSTM with Attention
- **Innovation**: Temporal attention over landmark sequences
- **Focus**: RNN-based alternative to GCNs
- **Performance**: Competitive accuracy with fewer params

**Key Features:**
- âœ… Bidirectional temporal encoding
- âœ… Multi-head attention mechanism
- âœ… Sequence-to-label classification
- âœ… Gradient clipping and dropout regularization

</td>
</tr>
</table>

<div align="center">

**ğŸ”¬ Research Status:** *Ongoing â€” Results under evaluation and paper preparation in progress*

[![Research Progress](https://img.shields.io/badge/Research-In%20Progress-yellow?style=for-the-badge&logo=google-scholar)](https://github.com/Muhammad-Huzifa)
[![Code Quality](https://img.shields.io/badge/Code-Production%20Ready-success?style=for-the-badge&logo=github)](https://github.com/Muhammad-Huzifa)

</div>

---

## ğŸ› ï¸ Technical Expertise

<div align="center">

### **Deep Learning Frameworks**

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

### **Computer Vision & AI**

![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0097A7?style=for-the-badge&logo=google&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=python&logoColor=white)

### **Development Tools**

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)

### **Architecture Specializations**

```python
research_expertise = {
    "Graph Neural Networks": {
        "Architectures": ["ST-GCN", "MS-GCN", "TT-STGCN", "Adaptive GCN"],
        "Techniques": ["Multi-scale convolution", "Temporal transformers", "Attention fusion"]
    },
    "Computer Vision": {
        "Tasks": ["Pose estimation", "Action recognition", "Gesture classification"],
        "Tools": ["MediaPipe Holistic", "OpenPose", "YOLO models"]
    },
    "Deep Learning": {
        "Models": ["Transformers", "BiLSTM", "CNN", "Hybrid architectures"],
        "Optimizations": ["Depthwise separable conv", "Parameter sharing", "Pruning"]
    },
    "Training Techniques": {
        "Regularization": ["Label smoothing", "Mixup", "Dropout", "Weight decay"],
        "Scheduling": ["Warmup", "Cosine annealing", "Step decay"],
        "Augmentation": ["Temporal masking", "Spatial dropout", "TTA (Test-Time Aug)"]
    }
}
```

</div>

---

## ğŸ“ˆ Research Impact & Metrics

<div align="center">

### **Model Performance Comparison**

| Model | Parameters | Accuracy | FPS | Deployment |
|-------|-----------|----------|-----|------------|
| **TT-STGCN** | 1.1M | **74%+** | 35-40 | âš¡ GPU |
| **Efficient TT-STGCN** | 267K | 71% | 55+ | ğŸ”‹ Edge |
| **BiLSTM + Attention** | ~4M | 68% | 45 | ğŸ’» CPU |
| **Baseline ST-GCN** | 600K | 67% | 40 | âš¡ GPU |

### **Dataset Scale**

- **Classes**: 300 (WLASL-300)
- **Training Samples**: 3,548
- **Validation Samples**: 900
- **Test Samples**: 668
- **Landmarks**: 65 (MediaPipe: 23 pose + 42 hands)

</div>

---

## ğŸ“‚ Other Projects & Implementations

<div align="center">

<a href="https://github.com/Muhammad-Huzifa/Machine_Learning">
  <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=Muhammad-Huzifa&repo=Machine_Learning&theme=radical&hide_border=true" />
</a>

</div>

### **Additional Work:**
- ğŸ¯ **Object Detection with YOLO** â€” Custom implementations for real-time detection
- ğŸ§  **Neural Networks from Scratch** â€” Building CNN/ANN architectures using NumPy
- ğŸ“Š **ML Foundations** â€” Comprehensive algorithm implementations (regression, classification, clustering)
- ğŸ”¬ **Pose Estimation Pipelines** â€” MediaPipe integration for landmark extraction

---

## ğŸ“Š GitHub Statistics

<div align="center">
  
<img height="180em" src="https://github-readme-stats.vercel.app/api?username=Muhammad-Huzifa&show_icons=true&theme=radical&hide_border=true&count_private=true&include_all_commits=true" />
<img height="180em" src="https://github-readme-stats.vercel.app/api/top-langs/?username=Muhammad-Huzifa&layout=compact&theme=radical&hide_border=true&langs_count=8" />

</div>

<div align="center">
  
[![GitHub Streak](https://streak-stats.demolab.com?user=Muhammad-Huzifa&theme=radical&hide_border=true&date_format=M%20j%5B%2C%20Y%5D)](https://git.io/streak-stats)

![Activity Graph](https://github-readme-activity-graph.vercel.app/graph?username=Muhammad-Huzifa&theme=react-dark&hide_border=true&area=true)

</div>

---

## ğŸ¯ Current Focus & Future Directions

<div align="center">

```mermaid
graph LR
    A[Current Work] --> B[TT-STGCN Optimization]
    A --> C[Paper Preparation]
    A --> D[Model Ensemble]
    
    B --> E[85%+ Accuracy Target]
    C --> F[Conference Submission]
    D --> G[Multi-Model Fusion]
    
    E --> H[Deploy to Production]
    F --> H
    G --> H
    
    style A fill:#9745F5
    style H fill:#00C853
```

</div>

### **Immediate Goals:**
- ğŸ¯ **Achieve 85%+ Top-1 Accuracy** on WLASL-300 (Currently: 85%+ with TT-STGCN)
- ğŸ“ **Prepare Research Paper** documenting architecture innovations
- ğŸ”¬ **Implement Ensemble Methods** (3-model fusion for +3-5% boost)
- ğŸš€ **Optimize Inference** for real-time deployment (<20ms latency)

### **Research Directions:**
- ğŸ§ª Self-distillation techniques (student-teacher learning)
- ğŸ”„ Continuous Sign Language Recognition (CSLR)
- ğŸŒ Cross-dataset generalization studies
- ğŸ“± Mobile deployment optimization (TensorFlow Lite, ONNX)

---

## ğŸ¤ Collaboration & Contact

<div align="center">

### **Open for Discussions On:**
ğŸ”¹ Sign Language Recognition Research  
ğŸ”¹ Graph Neural Networks & Transformers  
ğŸ”¹ Efficient Model Design & Optimization  
ğŸ”¹ Academic Collaborations & Paper Co-authorship  
ğŸ”¹ AI Engineering Opportunities  

---

### **Let's Connect!**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Muhammad_Huzifa-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/muhammad-huzifa3202/)
[![Email](https://img.shields.io/badge/Email-mhuzaifa3202@gmail.com-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:mhuzaifa3202@gmail.com)
[![Kaggle](https://img.shields.io/badge/Kaggle-Muhammad_Huzaifa-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/muhammadhuzaifa)
[![GitHub](https://img.shields.io/badge/GitHub-@Muhammad--Huzifa-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Muhammad-Huzifa)

**ğŸ“§ Direct Contact:** mhuzaifa3202@gmail.com  
**ğŸ’¼ LinkedIn:** [muhammad-huzifa3202](https://www.linkedin.com/in/muhammad-huzifa3202/)

</div>

---

<div align="center">
  
### ğŸ’¡ *"Building efficient AI systems that make deep learning research accessible and deployable."*

**ğŸ”¬ Research Philosophy:** Bridging the gap between cutting-edge research and practical applications through lightweight, interpretable, and scalable architectures.

â­ **Explore my repositories** to see production-ready implementations of state-of-the-art models!  
ğŸ¤ **Reach out** for collaborations on Deep Learning, Computer Vision, or Graph Neural Networks!

---

### ğŸ† Key Achievements

âœ… **74%+ Accuracy** on 300-class sign language recognition (TT-STGCN)  
âœ… **~1M Parameters** â€” Ultra-efficient model design  
âœ… **Real-time Inference** â€” <20ms latency on mid-tier GPUs  
âœ… **4 Research Repositories** â€” Complete implementations with documentation  
âœ… **Open-Source Contributions** â€” Reproducible research for the community  

</div>

---

<div align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=120&section=footer" width="100%"/>
  
  **â­ Star my repositories if you find them useful! â­**
  
</div>
